import os
import sys
import torch
from torchvision.transforms.functional import normalize, to_pil_image
from torchvision.transforms import ToTensor, Normalize
import matplotlib.pyplot as plt
import json
from models import get_model
from utils import resize_density_map, sliding_window_predict
from PIL import Image
import numpy as np
from scipy.ndimage import gaussian_filter
from sklearn.cluster import KMeans
import datetime
from typing import Optional
from typing import Union

project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(project_root)
os.environ['CUDA_LAUNCH_BLOCKING'] = "1"
os.environ["CUDA_VISIBLE_DEVICES"] = "0"
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class ClipEBC:
    """
    CLIP-EBC (Efficient Boundary Counting) ì´ë¯¸ì§€ ì²˜ë¦¬ í´ë˜ìŠ¤ì…ë‹ˆë‹¤.
    
    CLIP ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ë©°, ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì˜ˆì¸¡ ê¸°ëŠ¥ì„ í¬í•¨í•œ
    ë‹¤ì–‘í•œ ì„¤ì • ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    Attributes:
        truncation (int): ì˜ë¼ë‚´ê¸° ë§¤ê°œë³€ìˆ˜. ê¸°ë³¸ê°’ 4.
        reduction (int): ì¶•ì†Œ ë¹„ìœ¨. ê¸°ë³¸ê°’ 8.
        granularity (str): ì„¸ë¶„í™” ìˆ˜ì¤€. ê¸°ë³¸ê°’ "fine".
        anchor_points (str): ì•µì»¤ í¬ì¸íŠ¸ ë°©ë²•. ê¸°ë³¸ê°’ "average".
        model_name (str): CLIP ëª¨ë¸ ì´ë¦„. ê¸°ë³¸ê°’ "clip_vit_b_16".
        input_size (int): ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°. ê¸°ë³¸ê°’ 224.
        window_size (int): ìŠ¬ë¼ì´ë”© ìœˆë„ìš° í¬ê¸°. ê¸°ë³¸ê°’ 224.
        stride (int): ìŠ¬ë¼ì´ë”© ìœˆë„ìš° ì´ë™ ê°„ê²©. ê¸°ë³¸ê°’ 224.
        prompt_type (str): í”„ë¡¬í”„íŠ¸ ìœ í˜•. ê¸°ë³¸ê°’ "word".
        dataset_name (str): ë°ì´í„°ì…‹ ì´ë¦„. ê¸°ë³¸ê°’ "qnrf".
        num_vpt (int): ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ í† í° ìˆ˜. ê¸°ë³¸ê°’ 32.
        vpt_drop (float): ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ í† í° ë“œë¡­ì•„ì›ƒ ë¹„ìœ¨. ê¸°ë³¸ê°’ 0.0.
        deep_vpt (bool): ê¹Šì€ ë¹„ì£¼ì–¼ í”„ë¡¬í”„íŠ¸ í† í° ì‚¬ìš© ì—¬ë¶€. ê¸°ë³¸ê°’ True.
        mean (tuple): ì •ê·œí™”ë¥¼ ìœ„í•œ í‰ê· ê°’. ê¸°ë³¸ê°’ (0.485, 0.456, 0.406).
        std (tuple): ì •ê·œí™”ë¥¼ ìœ„í•œ í‘œì¤€í¸ì°¨ê°’. ê¸°ë³¸ê°’ (0.229, 0.224, 0.225).
    """
    
    def __init__(self,
                 truncation=4,
                 reduction=8,
                 granularity="fine",
                 anchor_points="average",
                 model_name="clip_vit_b_16",
                 input_size=224,
                 window_size=224,
                 stride=224,
                 prompt_type="word",
                 dataset_name="qnrf",
                 num_vpt=32,
                 vpt_drop=0.,
                 deep_vpt=True,
                 mean=(0.485, 0.456, 0.406),
                 std=(0.229, 0.224, 0.225),
                 config_dir="configs"):
        """CLIPEBC í´ë˜ìŠ¤ë¥¼ ì„¤ì • ë§¤ê°œë³€ìˆ˜ì™€ í•¨ê»˜ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.truncation = truncation
        self.reduction = reduction
        self.granularity = granularity
        self.anchor_points_type = anchor_points  # ì›ë˜ ì…ë ¥ê°’ ì €ì¥
        self.model_name = model_name
        self.input_size = input_size
        self.window_size = window_size
        self.stride = stride
        self.prompt_type = prompt_type
        self.dataset_name = dataset_name
        self.num_vpt = num_vpt
        self.vpt_drop = vpt_drop
        self.deep_vpt = deep_vpt
        self.mean = mean
        self.std = std
        self.config_dir = config_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        
        self.bins = None
        self.anchor_points = None
        self.model = None
        
        # ì´ˆê¸° ì„¤ì • ë¡œë“œ ë° ëª¨ë¸ ì´ˆê¸°í™”
        self._load_config()
        self._initialize_model()
        
    def _load_config(self):
        """ì„¤ì • íŒŒì¼ì„ ë¡œë“œí•˜ê³  binsì™€ anchor_pointsë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
        config_path = os.path.join(self.config_dir, f"reduction_{self.reduction}.json")
        with open(config_path, "r") as f:
            config = json.load(f)[str(self.truncation)][self.dataset_name]
        
        self.bins = config["bins"][self.granularity]
        self.bins = [(float(b[0]), float(b[1])) for b in self.bins]
        
        if self.anchor_points_type == "average":
            self.anchor_points = config["anchor_points"][self.granularity]["average"]
        else:
            self.anchor_points = config["anchor_points"][self.granularity]["middle"]
        self.anchor_points = [float(p) for p in self.anchor_points]
        
    def _initialize_model(self):
        """CLIP ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.model = get_model(
            backbone=self.model_name,
            input_size=self.input_size,
            reduction=self.reduction,
            bins=self.bins,
            anchor_points=self.anchor_points,
            prompt_type=self.prompt_type,
            num_vpt=self.num_vpt,
            vpt_drop=self.vpt_drop,
            deep_vpt=self.deep_vpt
        )

        ckpt_path = "assets/CLIP_EBC_nwpu_rmse.pth"
        ckpt = torch.load(ckpt_path, map_location=device)
        self.model.load_state_dict(ckpt)
        self.model = self.model.to(device)
        self.model.eval()

    def visualize_density_map(self, alpha: float = 0.5, save: bool = False, 
                            save_path: Optional[str] = None):
        """
        í˜„ì¬ ì €ì¥ëœ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            alpha (float): density mapì˜ íˆ¬ëª…ë„ (0~1). ê¸°ë³¸ê°’ 0.5
            save (bool): ì‹œê°í™” ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ False
            save_path (str, optional): ì €ì¥í•  ê²½ë¡œ. Noneì¼ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìë™ ìƒì„±ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥.
                ê¸°ë³¸ê°’ None
                
        Returns:
            Tuple[matplotlib.figure.Figure, np.ndarray]:
                - density mapì´ ì˜¤ë²„ë ˆì´ëœ matplotlib Figure ê°ì²´
                - RGB í˜•ì‹ì˜ ì‹œê°í™”ëœ ì´ë¯¸ì§€ ë°°ì—´ (H, W, 3)
        Raises:
            ValueError: density_map ë˜ëŠ” processed_imageê°€ Noneì¸ ê²½ìš° (predict ë©”ì„œë“œê°€ ì‹¤í–‰ë˜ì§€ ì•Šì€ ê²½ìš°)
        """
        if self.density_map is None or self.processed_image is None:
            raise ValueError("ë¨¼ì € predict ë©”ì„œë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        fig, ax = plt.subplots(dpi=200, frameon=False)
        ax.imshow(self.processed_image)
        ax.imshow(self.density_map, cmap="jet", alpha=alpha)
        ax.axis("off")
        
        if save:
            if save_path is None:
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                save_path = f"crowd_density_{timestamp}.png"
            
            # ì—¬ë°± ì œê±°í•˜ê³  ì €ì¥
            plt.savefig(save_path, bbox_inches='tight', pad_inches=0, dpi=200)
            print(f"Image saved to: {save_path}")
        
        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (4,))
        image_from_plot = image_from_plot[:,:,:3]  # RGBë¡œ ë³€í™˜
        
        return fig , image_from_plot
    
    def visualize_dots(self, dot_size: int = 20, sigma: float = 1, percentile: float = 97, 
                    save: bool = False, save_path: Optional[str] = None):
        """
        ì˜ˆì¸¡ëœ êµ°ì¤‘ ìœ„ì¹˜ë¥¼ ì ìœ¼ë¡œ í‘œì‹œí•˜ì—¬ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            dot_size (int): ì ì˜ í¬ê¸°. ê¸°ë³¸ê°’ 20
            sigma (float): Gaussian í•„í„°ì˜ sigma ê°’. ê¸°ë³¸ê°’ 1
            percentile (float): ì„ê³„ê°’ìœ¼ë¡œ ì‚¬ìš©í•  ë°±ë¶„ìœ„ìˆ˜ (0-100). ê¸°ë³¸ê°’ 97
            save (bool): ì‹œê°í™” ê²°ê³¼ë¥¼ ì´ë¯¸ì§€ë¡œ ì €ì¥í• ì§€ ì—¬ë¶€. ê¸°ë³¸ê°’ False
            save_path (str, optional): ì €ì¥í•  ê²½ë¡œ. Noneì¼ ê²½ìš° í˜„ì¬ ë””ë ‰í† ë¦¬ì— ìë™ ìƒì„±ëœ ì´ë¦„ìœ¼ë¡œ ì €ì¥.
                ê¸°ë³¸ê°’ None
                
        Returns:
            Tuple[matplotlib.backends.backend_agg.FigureCanvasBase, np.ndarray]: 
                - matplotlib figureì˜ canvas ê°ì²´
                - RGB í˜•ì‹ì˜ ì‹œê°í™”ëœ ì´ë¯¸ì§€ ë°°ì—´ (H, W, 3)
        Raises:
            ValueError: density_map ë˜ëŠ” processed_imageê°€ Noneì¸ ê²½ìš° (predict ë©”ì„œë“œê°€ ì‹¤í–‰ë˜ì§€ ì•Šì€ ê²½ìš°)
        """
        if self.density_map is None or self.processed_image is None:
            raise ValueError("ë¨¼ì € predict ë©”ì„œë“œë¥¼ ì‹¤í–‰í•˜ì—¬ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.")
            
        adjusted_pred_count = int(round(self.count))
        
        if adjusted_pred_count == 0:
            print("ğŸ’¡ ì˜ˆì¸¡ëœ êµ°ì¤‘ ìˆ˜ê°€ 0ì…ë‹ˆë‹¤. dot ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            return None, None

        fig, ax = plt.subplots(dpi=200, frameon=False)
        ax.imshow(self.processed_image)
        
        filtered_density = gaussian_filter(self.density_map, sigma=sigma)
        
        threshold = np.percentile(filtered_density, percentile)
        candidate_pixels = np.column_stack(np.where(filtered_density >= threshold))
        
        if len(candidate_pixels) > adjusted_pred_count:
            kmeans = KMeans(n_clusters=adjusted_pred_count, random_state=42, n_init=10)
            kmeans.fit(candidate_pixels)
            head_positions = kmeans.cluster_centers_.astype(int)
        else:
            head_positions = candidate_pixels
            
        y_coords, x_coords = head_positions[:, 0], head_positions[:, 1]
        ax.scatter(x_coords, y_coords, 
                    c='red',
                    s=dot_size,
                    alpha=1.0,
                    edgecolors='white',
                    linewidth=1)
        
        ax.axis("off")
        
        if save:
            if save_path is None:
                timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
                save_path = f"crowd_dots_{timestamp}.png"
            
            plt.savefig(save_path, bbox_inches='tight', pad_inches=0, dpi=200)
            print(f"Image saved to: {save_path}")
        
        # Figureë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
        fig.canvas.draw()
        image_from_plot = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)
        image_from_plot = image_from_plot.reshape(fig.canvas.get_width_height()[::-1] + (4,))
        image_from_plot = image_from_plot[:,:,:3]  # RGBë¡œ ë³€í™˜
        
        # plt.close(fig)
        # return image_from_plot
        return fig.canvas, image_from_plot
    
    def _process_image(self, image: Union[str, np.ndarray]) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ë¥¼ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ê²½ë¡œ, ë„˜íŒŒì´ ë°°ì—´, Streamlit UploadedFile ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤.
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€. ë‹¤ìŒ í˜•ì‹ ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤:
                - str: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
                - np.ndarray: (H, W, 3) í˜•íƒœì˜ RGB ì´ë¯¸ì§€
                - UploadedFile: Streamlitì˜ ì—…ë¡œë“œëœ íŒŒì¼
                    
        Returns:
            torch.Tensor: ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ í…ì„œ, shape (1, 3, H, W)
            
        Raises:
            ValueError: ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì´ ì…ë ¥ëœ ê²½ìš°
            Exception: ì´ë¯¸ì§€ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ëŠ” ê²½ìš°
        """
        to_tensor = ToTensor()
        normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        
        # ì›ë³¸ ì´ë¯¸ì§€ ì €ì¥
        self.original_image = image
        
        # ì…ë ¥ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
        if isinstance(image, str):
            # íŒŒì¼ ê²½ë¡œì¸ ê²½ìš°
            with open(image, "rb") as f:
                pil_image = Image.open(f).convert("RGB")
        elif isinstance(image, np.ndarray):
            # ë„˜íŒŒì´ ë°°ì—´ì¸ ê²½ìš°
            if image.dtype == np.uint8:
                pil_image = Image.fromarray(image)
            else:
                # float íƒ€ì…ì¸ ê²½ìš° [0, 1] ë²”ìœ„ë¡œ ê°€ì •í•˜ê³  ë³€í™˜
                pil_image = Image.fromarray((image * 255).astype(np.uint8))
        else:
            # Streamlit UploadedFile ë˜ëŠ” ê¸°íƒ€ íŒŒì¼ ê°ì²´ì¸ ê²½ìš°
            try:
                pil_image = Image.open(image).convert("RGB")
            except Exception as e:
                raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤: {type(image)}") from e
        
        # í…ì„œ ë³€í™˜ ë° ì •ê·œí™”
        tensor_image = to_tensor(pil_image)
        normalized_image = normalize(tensor_image)
        batched_image = normalized_image.unsqueeze(0)  # (1, 3, H, W)
        batched_image = batched_image.to(self.device)

        return batched_image
    def _post_process_image(self, image):
        """ì´ë¯¸ì§€ í›„ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        image = normalize(image, mean=(0., 0., 0.), 
                        std=(1. / self.std[0], 1. / self.std[1], 1. / self.std[2]))
        image = normalize(image, mean=(-self.mean[0], -self.mean[1], -self.mean[2]), 
                        std=(1., 1., 1.))
        processed_image = to_pil_image(image.squeeze(0))
        return processed_image

    @torch.no_grad()
    def predict(self, image: torch.Tensor) -> Image.Image:
        """
        ëª¨ë¸ ì¶œë ¥ ì´ë¯¸ì§€ì˜ í›„ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        
        Args:
            image (torch.Tensor): í›„ì²˜ë¦¬í•  ì´ë¯¸ì§€ í…ì„œ, shape (1, 3, H, W)
            
        Returns:
            PIL.Image.Image: í›„ì²˜ë¦¬ëœ PIL ì´ë¯¸ì§€
            
        Note:
            ì´ë¯¸ì§€ í…ì„œì— ëŒ€í•´ ì •ê·œí™”ë¥¼ ì—­ë³€í™˜í•˜ê³  PIL ì´ë¯¸ì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
            self.meanê³¼ self.std ê°’ì„ ì‚¬ìš©í•˜ì—¬ ì›ë³¸ ì´ë¯¸ì§€ì˜ ìŠ¤ì¼€ì¼ë¡œ ë³µì›í•©ë‹ˆë‹¤.
        """
        processed_image = self._process_image(image)
        image_height, image_width = processed_image.shape[-2:]
        processed_image = processed_image.to(self.device)
        
        pred_density = sliding_window_predict(self.model, processed_image, 
                                        self.window_size, self.stride)
        pred_count = pred_density.sum().item()
        resized_pred_density = resize_density_map(pred_density, 
                                                (image_height, image_width)).cpu()
        
        self.processed_image = self._post_process_image(processed_image)
        self.density_map = resized_pred_density.squeeze().numpy()
        self.count = pred_count
        
        return pred_count
    
    def crowd_count(self):
        """
        ê°€ì¥ ìµœê·¼ ì˜ˆì¸¡ì˜ êµ°ì¤‘ ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            float: ì˜ˆì¸¡ëœ êµ°ì¤‘ ìˆ˜
            None: ì•„ì§ ì˜ˆì¸¡ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        return self.count
    
    def get_density_map(self):
        """
        ê°€ì¥ ìµœê·¼ ì˜ˆì¸¡ì˜ ë°€ë„ ë§µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
        
        Returns:
            numpy.ndarray: ë°€ë„ ë§µ
            None: ì•„ì§ ì˜ˆì¸¡ì´ ìˆ˜í–‰ë˜ì§€ ì•Šì€ ê²½ìš°
        """
        return self.density_map
    